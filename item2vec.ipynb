{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec - SkipGram architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Skip-gram model architecture usually tries to predict the context words (surrounding words) given a target word "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/skipgram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec - Data Sampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/sampling.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(sequence, window_size):\n",
    "    \"\"\"\n",
    "    This function provides a sampling using a window strategy, the window moves on the sequence\n",
    "    of link_ids and the positives are selected in the scope of the window. e.g, if a list of sequence is\n",
    "    [1,2,3,4] and the window is 1, the samples are [(1,2), (2,1), (2,3), (3,2), (3,4), (4,3)], this function\n",
    "    returns zip* of the above list in the form of two lists, source and positive.\n",
    "    \"\"\"\n",
    "\n",
    "    number_of_tokens = len(sequence)\n",
    "    samples = []\n",
    "    for i in range(number_of_tokens):\n",
    "        nbr_inds = list(range(max(0, i - window_size), i)) + list(\n",
    "            range(i + 1, min(number_of_tokens, i + window_size + 1))\n",
    "        )\n",
    "        for j in nbr_inds:\n",
    "            samples.append((sequence[i], sequence[j]))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sequence = ['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog']\n",
    "sample_data(sequence, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map n-dimension vectors into vector space and take cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/vector_space.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import glob\n",
    "import re\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading session data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"data/data.parquet\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting by event time stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values('event_time_stamp')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representing the sequence of clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['product_id'] = data['product_id'].astype(str)\n",
    "session_seq = data.groupby('session_id')['product_id'].apply(list).reset_index(\n",
    ").rename(columns={'product_id':\"sequence_of_clicks\"})\n",
    "session_seq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_seq['sequence_length'] = session_seq['sequence_of_clicks'].apply(lambda x: len(x))\n",
    "session_seq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_seq['sequence_length'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_seq['sequence_length'].quantile(0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_seq = session_seq[session_seq['sequence_length'] <= session_seq['sequence_length'].quantile(0.95)]\n",
    "session_seq = session_seq[session_seq['sequence_length'] >= 2]\n",
    "session_seq['sequence_length'].plot.box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_seq['sequence_length'].value_counts().to_frame().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data(['1463503', '1418365', '1531480'],  2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running SkipGram (using fasttext) on the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_params = {\n",
    "            \"model\": \"skipgram\",\n",
    "            \"lr\": 0.05,\n",
    "            \"dim\": 100,\n",
    "            \"ws\": 3,\n",
    "            \"epoch\": 300,\n",
    "            \"minCount\": 1,\n",
    "            \"minn\": 3,\n",
    "            \"maxn\": 0,\n",
    "            \"neg\": 5,\n",
    "            \"wordNgrams\": 1,\n",
    "            \"loss\": \"ns\",\n",
    "            \"bucket\": 2000000,\n",
    "            \"thread\": 24,\n",
    "            \"lrUpdateRate\": 100,\n",
    "            \"t\": 0.0001,\n",
    "            \"verbose\": 2,\n",
    "        }\n",
    "sequence_txt_file = 'data/seq.txt'\n",
    "sequence = [' '.join(x) for x in session_seq['sequence_of_clicks'].values]\n",
    "np.savetxt(sequence_txt_file, sequence, fmt=\"%s\", encoding=\"utf-8\")\n",
    "model = fasttext.train_unsupervised(sequence_txt_file, **fasttext_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.vstack([model[x] for x in model.words])\n",
    "vocabs = model.words\n",
    "vectors_dict = dict(zip(vocabs, vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_dict['1531480']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    \"\"\"\n",
    "    Takes 2 ndarray and  a, b and returns the cosine similarity according\n",
    "    to the definition of the dot product.\n",
    "        a should be a single 1-d array\n",
    "        b should be a 2-d array\n",
    "    \"\"\"\n",
    "\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b, axis=1)\n",
    "    return np.dot(a, b.T) / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a hash table for (product_id, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('images/*.jpeg')\n",
    "file_dict = {}\n",
    "for file in files:\n",
    "    result = re.search('images/(.*).jpeg', file)\n",
    "    file_dict[result.group(1)] = file   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding similar item to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = cos_sim(vectors_dict['1556752'], vectors)\n",
    "sims = sorted(zip(vocabs, sims), key=lambda x: x[1], reverse=True)[:9]\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for product_id, sim in sims: \n",
    "    images.append(file_dict[product_id]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(images[0], cv2.IMREAD_COLOR)\n",
    "plt.imshow(img[:,:,::-1])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "i = 1\n",
    "for image in images[1:]:\n",
    "    img =  cv2.imread(image, cv2.IMREAD_COLOR)\n",
    "    ax = fig.add_subplot(3, 3, i)\n",
    "    plt.imshow(img[:,:,::-1])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate Nearest Neighbor (ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
